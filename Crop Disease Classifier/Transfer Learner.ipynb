{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70295 images belonging to 38 classes.\n",
      "Found 17572 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "traindir = 'train'\n",
    "validationdir = 'validation'\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1/255)\n",
    "batch_size=128\n",
    "train_iter = datagen.flow_from_directory(traindir, class_mode='categorical', batch_size=batch_size)\n",
    "val_iter = datagen.flow_from_directory(validationdir, class_mode='categorical', batch_size=batch_size)\n",
    "\n",
    "train_total=train_iter.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception is a pretrained base that uses an ensemble of convolutional networks under the hood. Why this works when a custom ensemble failed, I am not entirely clear on. Furthermore, inception is trained on ImageNet under the hood, which is not totally representative of the leaf dataset. My hope was that it would be close enough to carry over some knowledge of shapes and textures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "output = base_model.output\n",
    "output = layers.GlobalAveragePooling2D()(output)\n",
    "output = layers.Dense(512, activation='relu')(output)\n",
    "out = layers.Dense(38, activation='softmax')(output)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I briefly train the top few layers that I added above the pretrained base. The validation accuracy even here is not great, and while it shows a general trend upward, there are frequent steps down. 5 epochs are shown; even when the model goes out to 20 epochs, the validation accuracy does not go up substantially. This is a disappointing sign of either overfitting because the base model is too large, or it is not specialized enough on this data set. To remedy this, a whole new base trained on a more similar dataset would need to be found, or a custom ensemble could be used, as I previously attempted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "549/549 [==============================] - 577s 1s/step - loss: 0.8744 - acc: 0.7569 - val_loss: 3.8518 - val_acc: 0.3031\n",
      "Epoch 2/5\n",
      "549/549 [==============================] - 313s 571ms/step - loss: 0.3526 - acc: 0.8859 - val_loss: 2.8733 - val_acc: 0.4375\n",
      "Epoch 3/5\n",
      "549/549 [==============================] - 221s 403ms/step - loss: 0.2589 - acc: 0.9144 - val_loss: 2.9665 - val_acc: 0.4484\n",
      "Epoch 4/5\n",
      "549/549 [==============================] - 227s 414ms/step - loss: 0.2168 - acc: 0.9273 - val_loss: 3.1962 - val_acc: 0.4266\n",
      "Epoch 5/5\n",
      "549/549 [==============================] - 225s 409ms/step - loss: 0.1790 - acc: 0.9389 - val_loss: 3.9897 - val_acc: 0.3891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bcc0849d30>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_iter, steps_per_epoch=int(train_total/batch_size), epochs=5, \n",
    "                    validation_steps=5, validation_data=val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the top two modules of the network are unfrozen so they can be trained. These numbers were determined by looking at the network itself and determining which layers comprised the top two modules (not shown for simplicity's sake). The accuracy does improve noticeably when this is done; it improved more when the top two modules were unfrozen than when only the top module was unfrozen. This is a sign that the pretrained network itself is a limiter on performance; if I could, I would have liked to unfreeze progressively more of the top modules. I am sure that this would have substantially increased performance. In view of the fact, though, that the basic convolutional net was already getting great performance, and the fact that I did not want to turn my computer into a brick one more time by training too large a network, I decided to not unfreeze more of the layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "549/549 [==============================] - 398s 725ms/step - loss: 0.0211 - acc: 0.9966 - val_loss: 2.4610 - val_acc: 0.5375\n",
      "Epoch 2/5\n",
      "549/549 [==============================] - 320s 582ms/step - loss: 0.0199 - acc: 0.9972 - val_loss: 2.4783 - val_acc: 0.5375\n",
      "Epoch 3/5\n",
      "549/549 [==============================] - 263s 480ms/step - loss: 0.0188 - acc: 0.9974 - val_loss: 2.3223 - val_acc: 0.5391\n",
      "Epoch 4/5\n",
      "549/549 [==============================] - 259s 471ms/step - loss: 0.0174 - acc: 0.9977 - val_loss: 2.3585 - val_acc: 0.5500\n",
      "Epoch 5/5\n",
      "549/549 [==============================] - 264s 480ms/step - loss: 0.0165 - acc: 0.9979 - val_loss: 2.1031 - val_acc: 0.5766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bcdb851710>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_iter, steps_per_epoch=int(train_total/batch_size), epochs=5, \n",
    "                    validation_steps=5, validation_data=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
